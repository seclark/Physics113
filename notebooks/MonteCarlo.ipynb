{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Processes and Monte Carlo Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Set 3 explores some physics processes that require the use of random numbers. Today we will briefly introduce random numbers and a class of algorithms known as Monte Carlo methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, ConnectionPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random numbers\n",
    "\n",
    "Many applications call for the use of random numbers. In physics, some processes are described probabilistically but fundamentally random, e.g., radioactive decay. Classical (non-quantum) phenomena are not truly random, but are often described only statistically and best treated as random, e.g., Brownian motion. So we need a way of generating \"random\" numbers. What are often called \"random numbers\" in most programming applications are actually **pseudorandom numbers**, which are generated deterministically, by starting with some \"seed\" value and then applying some algorithm to come up with a number that seems random. Let's code up our own extremely simple version of a pseudorandom number generator. \n",
    "\n",
    "### Linear congruential random number generator\n",
    "\n",
    "Consider this equation:\n",
    "\n",
    "$$x' = (ax + c)~\\mathrm{mod}~m$$\n",
    "\n",
    "Where $a$, $c$, and $m$ are integer constants and $x$ is an integer variable. When you feed this program an integer $x$, it spits out another integer $x'$, which is then fed back in as $x$ to produce a new $x'$, and so forth. This process will produce a sequence of seemingly random numbers. \n",
    "\n",
    "&#128309; Code it up yourself, starting from the suggested constants below, and compute and store 100 values starting from the \"seed\" value of 1. Plot your random numbers as a scatter plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1664525\n",
    "c = 1013904223\n",
    "m = 2**32\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128310; Comment on your plot. Do the values appear random? Are they genuinely, truly random? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128309; By which of your constants would you need to divide your output to put all of your random numbers on the range $[0, 1)$? Try it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on out, we will use existing implementations of pseudorandom number generators that are much better than this one. Instead of pointing you to specific functions, take a look through the <a target=\"_blank\" rel=\"noopener noreferrer\"  href=\"https://docs.python.org/3/library/random.html#\">numpy random module</a>. \n",
    "\n",
    "&#128310; Pick out two functions that look useful and describe here what each does and what you might use it for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rock, Paper, Scissors\n",
    "\n",
    "&#128309; Practice using functions from the numpy `random` module by writing a function that will randomly return \"rock\", \"paper\", or \"scissors\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128310; Use your function to play a game of rock, paper, scissors, either against your function or against a classmate's function. Play best of five and report the results here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Integration \n",
    "\n",
    "Suppose we need to evaluate the integral \n",
    "\n",
    "$$I = \\int_0^2 \\sin^2 \\left[\\frac{1}{x(2-x)}\\right] dx$$\n",
    "\n",
    "&#128309; Plot the integrand on $(0, 2)$ and behold its pathological nature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128310; Early in this course we discussed numerical integration. How well do you think an algorithm like the trapezoidal rule is going to perform on this? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is **Monte Carlo integration**, which simply says: let's approximate the area under the curve by generating random numbers within some bounding area and asking if each is over or under the curve. In the limit of many samples, the *fraction* of points below the curve should approximately equal the integral. \n",
    "\n",
    "More specifically, let's say that for this example we are going to generate random numbers in the rectangle defined by an x-value between (0, 2) and a y-value between (0, 1). The area of this rectangle is $A = 2$, so if we sample uniformly at random in this rectangle, the probability that a point falls below our curve is $p = I/A$, where $I$ is the integral we want to approximate. We are going to approximate the probability $p$ by the fraction of $N$ points that fall below the curve: $p \\approx k/N$. So our approximation of the integral is\n",
    "\n",
    "$$I \\approx \\frac{kA}{N}$$\n",
    "\n",
    "&#128310; Check your understanding: what is $k$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128309; Use Monte Carlo integration to evaluate our pathological integral above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: connection to Physics 130\n",
    "\n",
    "&#128310; Those of you in Physics 130 this quarter might recall a discussion of <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://stanford.edu/class/physics130/coin/\">Schr√∂dinger's coin.</a> Describe in a few sentences how you would code up the quantum coin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Simulation\n",
    "\n",
    "A **Monte Carlo simulation** is a simulation that uses random numbers to simulate some physical process in order to estimate something about that process. Monte Carlo simulations are widely used in many applications you will come across, including in statistical mechanics, to estimate propagated error, and many classes of problems where one needs to sample a high-dimensional parameter space. In Problem Set 3 you are exploring a **Markov Chain Monte Carlo (MCMC)** method in some depth. Feel free to read through that problem first, if you haven't already -- or work through today's notebook but revisit it after tackling Problem Set 3 to appreciate more of the background behind Monte Carlo simulations and Markov chains. \n",
    "\n",
    "Today we will step you through an application of a Monte Carlo simulation to a **global optimization** problem, using a method known as **simulated annealing**. We have studied optimization problems already in this class -- recall our exploration of root-finding -- but the methods we explored were suitable for finding *local* minima or maxima, and did not guarantee that the solution was the global minimum or maximum. Often we need to solve a global optimization problem -- e.g., if we want to find the ground state energy of a quantum system, we are looking for the overall minimum of the energy. Global optimization is a difficult task computationally! \n",
    "\n",
    "### Simulated annealing\n",
    "\n",
    "Glassworkers, metalworkers, etc. are familiar with the fact that rapidly cooling hot materials like glass or metal causes defects that weaken the materials. This happens because the system gets trapped in a local minimum of the energy -- just as a Monte Carlo simulation could get trapped in an energy minimum. \"Annealing\" is the process of slowly cooling materials so that they end up strong. Simulated annealing is an approach to global optimization that mimics this physical process by using a Monte Carlo simulation with a temperature parameter that is gradually lowered from some initially high value toward zero. One can prove that if the cooling is slow enough, this will converge to the ground state, i.e., the global minimum, though of course as usual we will need to find a compromise between \"slow enough\" and having our program run in a reasonable amount of time. \n",
    "\n",
    "Simulated annealing is perhaps most famous as a method for solving the *traveling salesman problem*, an optimization problem in which a salesperson starts at home and needs to find the shortest path that visits a set number of cities exactly once before returning home. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dimer covering problem\n",
    "\n",
    "A dimer is a two-atom polymer. Often in condensed matter physics one wants to place dimers on the surface of some solid that defines a grid. No two dimers can overlap. The question is how many dimers can fit on the lattice (this is going to be obvious for the problem below but it is not always obvious in practice)! \n",
    "\n",
    "Use simulated annealing to solve the dimer problem on an L x L lattice. The \"energy\" function for this system is the negative of the number of dimers, such that this energy is minimized when there is a maximum number of dimers. Read more about this in Problem Set 3, Problem 4. The moves for the Markov chain are the following:\n",
    "\n",
    "1. Choose two adjacent sites on the lattice at random.\n",
    "2. If those two sites are currently both empty, place a dimer on them.\n",
    "3. If the two sites are currently occupied by a single dimer, remove the dimer from the lattice with the probability $e^{-1/T}$. (Here we are just giving you this probability, but read through Problem Set 3 and convince yourself that this is correct.)\n",
    "4. Otherwise, do nothing. \n",
    "\n",
    "&#128309; Implement and visualize this using the comments and starter code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lattice: use (capital) L for the length of the lattice. Start with L = 15\n",
    "\n",
    "\n",
    "# Create an L x L array of integer zeros called (lowercase) s to store an index representing each dimer. \n",
    "\n",
    "\n",
    "# We will use capital T for the temperature. Start with Tmax = 5.0 and Tmin = 1E-2.\n",
    "Tmax = 5.0\n",
    "Tmin = 1E-2\n",
    "\n",
    "# Initialize tau to 1E4\n",
    "tau = 1E4\n",
    "\n",
    "# We will use dimer_indx to keep track of the dimers. Start with dimer_indx = 0\n",
    "dimer_indx = 0\n",
    "\n",
    "# Let's also count the dimers. Start with n_dimers = 0\n",
    "n_dimers = 0\n",
    "\n",
    "# This is for drawing the dimers\n",
    "radius = 0.2\n",
    "all_sites1 = {}\n",
    "all_sites2 = {}\n",
    "all_connectors = {}\n",
    "\n",
    "dimer_grid = np.zeros((L, L))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(dimer_grid, cmap='binary')\n",
    "\n",
    "# Set our original temperature (capital) T to (capital) Tmax\n",
    "T = Tmax\n",
    "\n",
    "# We will use lowercase t for the time. Set the time t to 0.\n",
    "t = 0\n",
    "\n",
    "# We will use a while loop to simulate the annealing process. \n",
    "# We will continue the loop while temperature (uppercase) T is greater than Tmin.\n",
    "while (T > Tmin): \n",
    "\n",
    "    # Cooling: increment (lowercase) t by 1 and set (uppercase) T to Tmax * exp(-t/tau), where the t in the exponential is lowercase.\n",
    "\n",
    "    \n",
    "    # Use a random number to decide whether to try to add a vertical dimer or a horizontal dimer\n",
    "    if # your code here:\n",
    "        # If we're adding a vertical dimer, pick an x index of the lattice at random, and assign it to (lowercase) i1 and i2, \n",
    "        # the indices of both ends of the dimer. \n",
    "        \n",
    "\n",
    "        # Pick a random y index, j1, and set j2 to be the next y index (j1 + 1)\n",
    "        \n",
    "    \n",
    "    # Perform the same steps as above, but for a horizontal dimer\n",
    "    else:\n",
    "        \n",
    "\n",
    "    # Check whether s[i1, j1] is equal to s[i2, j2]\n",
    "    if # your code here:\n",
    "\n",
    "        # If both sites in the grid are 0, we will add a dimer here. Increment dimer_indx and set them equal to a new dimer\n",
    "        if s[i1, j1] == 0:\n",
    "            # Increment (add one to) dimer_indx, which we are using to index each dimer we add.\n",
    "            \n",
    "\n",
    "            # Set the value of s at these indices to dimer_indx\n",
    "            \n",
    "\n",
    "            # Increment (add one to) n_dimers, our count of the total dimers, since we just added one\n",
    "        \n",
    "\n",
    "            # The following is one way of plotting these dimers\n",
    "            all_sites1[dimer_indx] = Circle((i1, j1), radius=radius)\n",
    "            all_sites2[dimer_indx] = Circle((i2, j2), radius=radius)\n",
    "            all_connectors[dimer_indx] = ConnectionPatch((i1, j1), (i2, j2), 'data', 'data', arrowstyle='-', color=\"red\")\n",
    "\n",
    "        # If the sites are not equal, we will try to remove a dimer. \n",
    "        # Find a random number between 0 and 1. If it is less than exp(-1/T), remove the dimer. Otherwise nothing happens.\n",
    "        elif # your code here:\n",
    "            # Find the dimer index of the dimer to remove\n",
    "\n",
    "\n",
    "            # Set s at both of the dimer indices to 0\n",
    "\n",
    "\n",
    "            # Decrement (remove one from) n_dimers, since we just removed one\n",
    "            \n",
    "            \n",
    "            # Remove the dimer from the plot\n",
    "            all_sites1.pop(dimer_to_remove)\n",
    "            all_sites2.pop(dimer_to_remove)\n",
    "            all_connectors.pop(dimer_to_remove)\n",
    "\n",
    "# Plot your dimers\n",
    "[ax.add_patch(all_connectors[d]) for d in all_connectors.keys()];\n",
    "[ax.add_patch(all_sites1[d]) for d in all_sites1.keys()];\n",
    "[ax.add_patch(all_sites2[d]) for d in all_sites2.keys()];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128310; Increase and decrease `tau` by an order of magnitude or more and rerun your code. Which way (increasing or decreasing) makes your code run faster? Which way gives you better solutions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128309; *(Optional:)* For added fun, see if you can animate the process of placing your dimers on the lattice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgments\n",
    "\n",
    "S.E. Clark, with problems adapted from Newman 2013"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
